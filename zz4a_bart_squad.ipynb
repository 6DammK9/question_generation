{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pipelines import pipeline\n",
    "from nlgeval import compute_metrics\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\User\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = load_dataset('squad', split=['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 295/295 [00:00<00:00, 74.4kB/s]\n",
      "Downloading: 100%|██████████| 1.64k/1.64k [00:00<00:00, 561kB/s]\n",
      "Downloading: 100%|██████████| 780k/780k [00:01<00:00, 582kB/s]  \n",
      "Downloading: 100%|██████████| 446k/446k [00:01<00:00, 384kB/s]  \n",
      "Downloading: 100%|██████████| 15.0/15.0 [00:00<00:00, 4.96kB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 60.2kB/s]\n",
      "Downloading: 100%|██████████| 532M/532M [00:27<00:00, 20.3MB/s]   \n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"question-generation\", model=\"p208p2002/bart-squad-qg-hl\", ans_model=\"p208p2002/bart-squad-qg-hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_model = \"bart-squad-qg-hl\"\n",
    "qg_dataset = \"SQuAD v1.1\"\n",
    "res_dir = \"./results/bart-squad-qg-hl/\"\n",
    "\n",
    "Path(res_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hyp = res_dir + 'hyp.txt'\n",
    "ref = res_dir + 'ref1.txt'\n",
    "ctx = res_dir + 'ref2.txt'\n",
    "res = res_dir + 'res.json'\n",
    "\n",
    "dev_mode = False\n",
    "squad_size = 200 if dev_mode else len(valid_dataset)\n",
    "\n",
    "cqc = \"\" #Current concatenated questions\n",
    "ccc = \"\" #Current context\n",
    "\n",
    "h_q = [] #Lines of predicted question (concated by each topic)\n",
    "r_q = [] #Lines of actual question (concated by each topic)\n",
    "c_c = [] #Lines of context (for each topic)\n",
    "\n",
    "c_m = [] #Context-index mapping\n",
    "cmc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wq(ta, xt=hyp):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        for t in tqdm(ta):\n",
    "            nt = nlp(t)\n",
    "            f.writelines([' '.join(nt), '\\n'])\n",
    "\n",
    "def wc(ta, xt=ref):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        f.writelines('\\n'.join(ta))\n",
    "\n",
    "def label_answer_from_context_squad(dataset = valid_dataset, index= 0, highlight = \"[HL]\"):\n",
    "    answer = dataset[index][\"answers\"]['text'][0]\n",
    "    return dataset[index][\"context\"].replace(answer, \"%s%s%s\" % (highlight, answer, highlight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QG for 10570 records: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:02<00:00, 4733.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct context found: 2067\n",
      "Writing ./results/bart-squad-qg-hl/ref1.txt...\n",
      "Writing ./results/bart-squad-qg-hl/ref2.txt...\n"
     ]
    }
   ],
   "source": [
    "print(\"QG for {0} records: \".format(squad_size))\n",
    "\n",
    "for i in tqdm(range(0, squad_size)):\n",
    "    t_d = valid_dataset[i]\n",
    "    #Preprocessing. strip() fails btw\n",
    "    tdc = t_d[\"context\"].replace(\"\\n\", \"\")\n",
    "\n",
    "    #Fill in first context\n",
    "    if i == 0:\n",
    "        ccc = tdc\n",
    "\n",
    "    #Force write result when it reaches the end\n",
    "    if i == squad_size:\n",
    "        ccc = \"\"\n",
    "\n",
    "    #print(len(ccc), len(t_d[\"context\"]))\n",
    "\n",
    "    #Skip if no context swap\n",
    "    if tdc == ccc:\n",
    "        cqc = cqc + \"{} \".format(t_d[\"question\"])\n",
    "        cmc.append(i)\n",
    "        if i < squad_size - 1:\n",
    "            continue\n",
    "\n",
    "    #Context switched. Instead of calling QG pipeline instantly, we save for later execution.\n",
    "    r_q.append(cqc)\n",
    "    c_c.append(ccc)\n",
    "    c_m.append(cmc)\n",
    "    \n",
    "    #Swap context. \n",
    "    ccc = tdc\n",
    "    #Clear question segment and fill in first question segment\n",
    "    cqc = \"{} \".format(t_d[\"question\"])\n",
    "    cmc = []\n",
    "    cmc.append(i)\n",
    "\n",
    "print(\"Distinct context found: {0}\".format(len(c_c)))\n",
    "print(\"Writing {0}...\".format(ref))\n",
    "wc(r_q, xt=ref)\n",
    "print(\"Writing {0}...\".format(ctx))\n",
    "wc(c_c, xt=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2067/2067 [2:40:52<00:00,  4.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./results/bart-squad-qg-hl/hyp.txt...\n"
     ]
    }
   ],
   "source": [
    "#for ccc in tqdm(c_c):\n",
    "h_q = []\n",
    "def qg_batch(cmc):\n",
    "    hq = []\n",
    "    for ci in cmc:\n",
    "        c_q = nlp(label_answer_from_context_squad(index= ci))\n",
    "        for cq in c_q:\n",
    "            hq.append(cq[\"question\"])\n",
    "    return ' '.join(hq)\n",
    "\n",
    "#h_q = Parallel(n_jobs=1, verbose=0)(delayed(qg_single)(cq) for cq in tqdm(c_c))\n",
    "for cmc in tqdm(c_m):\n",
    "    #print(cmc)\n",
    "    h_q.append(qg_batch(cmc))\n",
    "\n",
    "print(\"Writing {0}...\".format(hyp))\n",
    "wc(h_q, xt=hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.639967\n",
      "Bleu_2: 0.482271\n",
      "Bleu_3: 0.373416\n",
      "Bleu_4: 0.294501\n",
      "METEOR: 0.275821\n",
      "ROUGE_L: 0.394924\n",
      "CIDEr: 0.387541\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = compute_metrics(hypothesis=hyp, references=[ref, ctx], no_skipthoughts=True, no_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing result to ./results/bart-squad-qg-hl/res.json...\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing result to {0}...\".format(res))\n",
    "\n",
    "res_dict = metrics_dict.copy()\n",
    "res_dict[\"Model\"] = qg_model\n",
    "res_dict[\"Dataset\"] = qg_dataset\n",
    "json_res = json.dumps(res_dict, indent = 4) \n",
    "with open(res, 'w+', encoding='utf-8') as f:\n",
    "    f.writelines(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47498515ab12efa1b601cdba97f63393ba71a785e03ed8d0031866b5c777e044"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
