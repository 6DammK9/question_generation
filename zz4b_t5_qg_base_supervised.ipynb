{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pipelines import pipeline\n",
    "from nlgeval import compute_metrics\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\User\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 83.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = load_dataset('squad', split=['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\", ans_model=\"valhalla/t5-base-qa-qg-hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_model = \"t5-base-qg-hl-supervised\"\n",
    "qg_dataset = \"SQuAD v1.1\"\n",
    "res_dir = \"./results/t5-base-qg-hl-supervised/\"\n",
    "\n",
    "Path(res_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hyp = res_dir + 'hyp.txt'\n",
    "ref = res_dir + 'ref1.txt'\n",
    "ctx = res_dir + 'ref2.txt'\n",
    "res = res_dir + 'res.json'\n",
    "\n",
    "dev_mode = False\n",
    "squad_size = 200 if dev_mode else len(valid_dataset)\n",
    "\n",
    "cqc = \"\" #Current concatenated questions\n",
    "ccc = \"\" #Current context\n",
    "\n",
    "h_q = [] #Lines of predicted question (concated by each topic)\n",
    "r_q = [] #Lines of actual question (concated by each topic)\n",
    "c_c = [] #Lines of context (for each topic)\n",
    "\n",
    "c_m = [] #Context-index mapping\n",
    "cmc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wq(ta, xt=hyp):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        for t in tqdm(ta):\n",
    "            nt = nlp(t)\n",
    "            f.writelines([' '.join(nt), '\\n'])\n",
    "\n",
    "def wc(ta, xt=ref):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        f.writelines('\\n'.join(ta))\n",
    "\n",
    "def label_answer_from_context_squad(dataset = valid_dataset, index= 0, highlight = \"<hl>\"):\n",
    "    answer = dataset[index][\"answers\"]['text'][0]\n",
    "    return dataset[index][\"context\"].replace(answer, \"%s%s%s\" % (highlight, answer, highlight))\n",
    "\n",
    "def unique_results(raw_result):\n",
    "    uniq = []\n",
    "    res = []\n",
    "    for rr in raw_result:\n",
    "        if rr[\"answer\"] not in uniq:\n",
    "            uniq.append(rr[\"answer\"])\n",
    "            res.append(rr)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QG for 200 records: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 4651.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct context found: 10\n",
      "Writing ./results/t5-base-qg-hl-supervised/ref1.txt...\n",
      "Writing ./results/t5-base-qg-hl-supervised/ref2.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"QG for {0} records: \".format(squad_size))\n",
    "\n",
    "for i in tqdm(range(0, squad_size)):\n",
    "    t_d = valid_dataset[i]\n",
    "    #Preprocessing. strip() fails btw\n",
    "    tdc = t_d[\"context\"].replace(\"\\n\", \"\")\n",
    "\n",
    "    #Fill in first context\n",
    "    if i == 0:\n",
    "        ccc = tdc\n",
    "\n",
    "    #Force write result when it reaches the end\n",
    "    if i == squad_size:\n",
    "        ccc = \"\"\n",
    "\n",
    "    #print(len(ccc), len(t_d[\"context\"]))\n",
    "\n",
    "    #Skip if no context swap\n",
    "    if tdc == ccc:\n",
    "        cqc = cqc + \"{} \".format(t_d[\"question\"])\n",
    "        cmc.append(i)\n",
    "        if i < squad_size - 1:\n",
    "            continue\n",
    "\n",
    "    #Context switched. Instead of calling QG pipeline instantly, we save for later execution.\n",
    "    r_q.append(cqc)\n",
    "    c_c.append(ccc)\n",
    "    c_m.append(cmc)\n",
    "    \n",
    "    #Swap context. \n",
    "    ccc = tdc\n",
    "    #Clear question segment and fill in first question segment\n",
    "    cqc = \"{} \".format(t_d[\"question\"])\n",
    "    cmc = []\n",
    "    cmc.append(i)\n",
    "\n",
    "print(\"Distinct context found: {0}\".format(len(c_c)))\n",
    "print(\"Writing {0}...\".format(ref))\n",
    "wc(r_q, xt=ref)\n",
    "print(\"Writing {0}...\".format(ctx))\n",
    "wc(c_c, xt=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:02<00:00, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./results/t5-base-qg-hl-supervised/hyp.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for ccc in tqdm(c_c):\n",
    "h_q = []\n",
    "def qg_batch(cmc):\n",
    "    hq = []\n",
    "    for ci in cmc:\n",
    "        c_q = nlp(label_answer_from_context_squad(index = ci))\n",
    "        for cq in c_q:\n",
    "            hq.append(cq[\"question\"])\n",
    "    return ' '.join(np.unique(hq))\n",
    "\n",
    "#h_q = Parallel(n_jobs=1, verbose=0)(delayed(qg_single)(cq) for cq in tqdm(c_c))\n",
    "for cmc in tqdm(c_m):\n",
    "    #print(cmc)\n",
    "    h_q.append(qg_batch(cmc))\n",
    "\n",
    "print(\"Writing {0}...\".format(hyp))\n",
    "wc(h_q, xt=hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.714758\n",
      "Bleu_2: 0.555005\n",
      "Bleu_3: 0.422875\n",
      "Bleu_4: 0.325291\n",
      "METEOR: 0.261611\n",
      "ROUGE_L: 0.273712\n",
      "CIDEr: 0.161833\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = compute_metrics(hypothesis=hyp, references=[ref, ctx], no_skipthoughts=True, no_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing result to ./results/t5-base-qg-hl-supervised/res.json...\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing result to {0}...\".format(res))\n",
    "\n",
    "res_dict = metrics_dict.copy()\n",
    "res_dict[\"Model\"] = qg_model\n",
    "res_dict[\"Dataset\"] = qg_dataset\n",
    "json_res = json.dumps(res_dict, indent = 4) \n",
    "with open(res, 'w+', encoding='utf-8') as f:\n",
    "    f.writelines(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47498515ab12efa1b601cdba97f63393ba71a785e03ed8d0031866b5c777e044"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
