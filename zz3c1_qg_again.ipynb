{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pipelines import pipeline\n",
    "from nlgeval import compute_metrics\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\User\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 91.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = load_dataset('squad', split=['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"question-generation\") #pipeline(\"e2e-qg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_model = \"t5-small-qg-hl\"\n",
    "qg_dataset = \"SQuAD v1.1\"\n",
    "res_dir = \"./results/t5-small-qg-hl/\"\n",
    "\n",
    "Path(res_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hyp = res_dir + 'hyp.txt'\n",
    "ref = res_dir + 'ref1.txt'\n",
    "ctx = res_dir + 'ref2.txt'\n",
    "res = res_dir + 'res.json'\n",
    "\n",
    "dev_mode = False\n",
    "squad_size = 200 if dev_mode else len(valid_dataset)\n",
    "\n",
    "#corpus = [text, text2,text3, text4]\n",
    "c_t = None #Current Title\n",
    "c_q = [] #Current QG set\n",
    "cqc = \"\" #Current concatenated questions\n",
    "ccc = \"\" #Current context\n",
    "\n",
    "h_q = [] #Lines of predicted question (concated by each topic)\n",
    "r_q = [] #Lines of actual question (concated by each topic)\n",
    "c_c = [] #Lines of context (for each topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wq(ta, xt=hyp):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        for t in tqdm(ta):\n",
    "            nt = nlp(t)\n",
    "            f.writelines([' '.join(nt), '\\n'])\n",
    "\n",
    "def wc(ta, xt=ref):\n",
    "    with open(xt, 'w+', encoding='utf-8') as f:\n",
    "        f.writelines('\\n'.join(ta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QG for 10570 records: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:02<00:00, 4795.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct context found: 2067\n",
      "Writing ./results/t5-small-qg-hl/ref1.txt...\n",
      "Writing ./results/t5-small-qg-hl/ref2.txt...\n"
     ]
    }
   ],
   "source": [
    "print(\"QG for {0} records: \".format(squad_size))\n",
    "\n",
    "for i in tqdm(range(0, squad_size)):\n",
    "    t_d = valid_dataset[i]\n",
    "    #Preprocessing. strip() fails btw\n",
    "    tdc = t_d[\"context\"].replace(\"\\n\", \"\")\n",
    "\n",
    "    #Fill in first context\n",
    "    if i == 0:\n",
    "        ccc = tdc\n",
    "\n",
    "    #Force write result when it reaches the end\n",
    "    if i == squad_size:\n",
    "        ccc = \"\"\n",
    "\n",
    "    #print(len(ccc), len(t_d[\"context\"]))\n",
    "\n",
    "    #Skip if no context swap\n",
    "    if tdc == ccc:\n",
    "        cqc = cqc + \"{} \".format(t_d[\"question\"])\n",
    "        if i < squad_size - 1:\n",
    "            continue\n",
    "    \n",
    "    #Fill in first question segment\n",
    "    if len(cqc) == 0:\n",
    "        cqc = cqc + \"{} \".format(t_d[\"question\"])\n",
    "    \n",
    "    #Context switched. Instead of calling QG pipeline instantly, we save for later execution.\n",
    "    r_q.append(cqc)\n",
    "    c_c.append(ccc)\n",
    "    \n",
    "    #Swap context. \n",
    "    ccc = tdc\n",
    "    #Clear question segment\n",
    "    cqc = \"\"\n",
    "\n",
    "print(\"Distinct context found: {0}\".format(len(c_c)))\n",
    "print(\"Writing {0}...\".format(ref))\n",
    "wc(r_q, xt=ref)\n",
    "print(\"Writing {0}...\".format(ctx))\n",
    "wc(c_c, xt=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2067/2067 [33:55<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./results/t5-small-qg-hl/hyp.txt...\n"
     ]
    }
   ],
   "source": [
    "#for ccc in tqdm(c_c):\n",
    "h_q = []\n",
    "def qg_single(ccc):\n",
    "    c_q = nlp(ccc)    \n",
    "    return ' '.join(cq[\"question\"] for cq in c_q)\n",
    "    #return ' '.join(c_q)\n",
    "\n",
    "#h_q = Parallel(n_jobs=1, verbose=0)(delayed(qg_single)(cq) for cq in tqdm(c_c))\n",
    "for cq in tqdm(c_c):\n",
    "    #print(cq)\n",
    "    h_q.append(qg_single(cq))\n",
    "\n",
    "print(\"Writing {0}...\".format(hyp))\n",
    "wc(h_q, xt=hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.674076\n",
      "Bleu_2: 0.513275\n",
      "Bleu_3: 0.404759\n",
      "Bleu_4: 0.326496\n",
      "METEOR: 0.208759\n",
      "ROUGE_L: 0.345611\n",
      "CIDEr: 0.113375\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = compute_metrics(hypothesis=hyp, references=[ref, ctx], no_skipthoughts=True, no_glove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing result to ./results/t5-small-qg-hl/res.json...\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing result to {0}...\".format(res))\n",
    "\n",
    "res_dict = metrics_dict.copy()\n",
    "res_dict[\"Model\"] = qg_model\n",
    "res_dict[\"Dataset\"] = qg_dataset\n",
    "json_res = json.dumps(res_dict, indent = 4) \n",
    "with open(res, 'w+', encoding='utf-8') as f:\n",
    "    f.writelines(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47498515ab12efa1b601cdba97f63393ba71a785e03ed8d0031866b5c777e044"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
